{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ”¸ https://github.com/BeeGass/HiPPO-Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py311/bin/python\n"
     ]
    }
   ],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: jax in /root/miniconda3/envs/py311/lib/python3.11/site-packages (0.4.23)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /root/miniconda3/envs/py311/lib/python3.11/site-packages (from jax) (0.3.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /root/miniconda3/envs/py311/lib/python3.11/site-packages (from jax) (1.26.2)\n",
      "Requirement already satisfied: opt-einsum in /root/miniconda3/envs/py311/lib/python3.11/site-packages (from jax) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in /root/miniconda3/envs/py311/lib/python3.11/site-packages (from jax) (1.11.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -q --upgrade pip\n",
    "! pip install -q einops\n",
    "! pip install -q tqdm\n",
    "\n",
    "! pip install jax \n",
    "! pip install -q jaxlib flax jaxtyping typing-extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/usr/local/cuda-12.3/bin:/root/miniconda3/envs/py311/bin:/root/miniconda3/condabin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "env: LD_LIBRARY_PATH=/usr/local/cuda-12.3/lib64:\n"
     ]
    }
   ],
   "source": [
    "# Capture the current PATH\n",
    "CURR_PATH = !echo $PATH\n",
    "CURR_PATH = CURR_PATH[0]  # Get the string value\n",
    "\n",
    "# Set the new PATH\n",
    "%env PATH=/usr/local/cuda-12.3/bin:{CURR_PATH}\n",
    "\n",
    "# Capture the current LD_LIBRARY_PATH\n",
    "CURR_LD_LIB_PATH = !echo $LD_LIBRARY_PATH\n",
    "CURR_LD_LIB_PATH = CURR_LD_LIB_PATH[0] if CURR_LD_LIB_PATH else \"\"\n",
    "\n",
    "# Set the new LD_LIBRARY_PATH\n",
    "%env LD_LIBRARY_PATH=/usr/local/cuda-12.3/lib64:{CURR_LD_LIB_PATH}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-12.3/bin:/root/miniconda3/envs/py311/bin:/root/miniconda3/condabin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n"
     ]
    }
   ],
   "source": [
    "! echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_FLAGS=--xla_dump_to=/tmp/why_is_this_slow.txt\n"
     ]
    }
   ],
   "source": [
    "JIT = True  # Set to False to disable JIT\n",
    "\n",
    "if JIT:\n",
    "    # TODO: set JIT=True and inspect this logfile\n",
    "    # takes > 30min to generate on my macbook\n",
    "    %env XLA_FLAGS=--xla_dump_to=/tmp/why_is_this_slow.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module_path = os.path.abspath(os.path.join(\"../../../../\"))\n",
    "# print(f\"module_path: {module_path}\")\n",
    "# if module_path not in sys.path:\n",
    "#     print(f\"Adding {module_path} to sys.path\")\n",
    "#     sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"False\"\n",
    "os.environ[\"TF_FORCE_UNIFIED_MEMORY\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "from flax.linen.activation import sigmoid, tanh, relu\n",
    "import numpy as np\n",
    "# import torch\n",
    "from flax.training import train_state  # , orbax_utils\n",
    "import orbax.checkpoint as ocp\n",
    "import optax\n",
    "from jaxtyping import install_import_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cuda(id=0)]\n"
     ]
    }
   ],
   "source": [
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Fri_Jan__6_16:45:21_PST_2023\n",
      "Cuda compilation tools, release 12.0, V12.0.140\n",
      "Build cuda_12.0.r12.0/compiler.32267302_0\n"
     ]
    }
   ],
   "source": [
    "! nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 28 22:11:11 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:28:00.0 Off |                  N/A |\n",
      "| 60%   30C    P2              N/A /  N/A |    919MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ii  cuda-cccl-12-0                  12.0.140-1                        amd64        CUDA CCCL\n",
      "ii  cuda-command-line-tools-12-0    12.0.1-1                          amd64        CUDA command-line tools\n",
      "ii  cuda-compat-12-0                525.147.05-1                      amd64        CUDA Compatibility Platform\n",
      "ii  cuda-compiler-12-0              12.0.1-1                          amd64        CUDA compiler\n",
      "ii  cuda-cudart-12-0                12.0.146-1                        amd64        CUDA Runtime native Libraries\n",
      "ii  cuda-cudart-dev-12-0            12.0.146-1                        amd64        CUDA Runtime native dev links, headers\n",
      "ii  cuda-cuobjdump-12-0             12.0.140-1                        amd64        CUDA cuobjdump\n",
      "ii  cuda-cupti-12-0                 12.0.146-1                        amd64        CUDA profiling tools runtime libs.\n",
      "ii  cuda-cupti-dev-12-0             12.0.146-1                        amd64        CUDA profiling tools interface.\n",
      "ii  cuda-cuxxfilt-12-0              12.0.140-1                        amd64        CUDA cuxxfilt\n",
      "ii  cuda-driver-dev-12-0            12.0.146-1                        amd64        CUDA Driver native dev stub library\n",
      "ii  cuda-gdb-12-0                   12.0.140-1                        amd64        CUDA-GDB\n",
      "ii  cuda-libraries-12-0             12.0.1-1                          amd64        CUDA Libraries 12.0 meta-package\n",
      "ii  cuda-libraries-dev-12-0         12.0.1-1                          amd64        CUDA Libraries 12.0 development meta-package\n",
      "ii  cuda-minimal-build-12-0         12.0.1-1                          amd64        Minimal CUDA 12.0 toolkit build packages.\n",
      "ii  cuda-nsight-compute-12-0        12.0.1-1                          amd64        NVIDIA Nsight Compute\n",
      "ii  cuda-nvcc-12-0                  12.0.140-1                        amd64        CUDA nvcc\n",
      "ii  cuda-nvdisasm-12-0              12.0.140-1                        amd64        CUDA disassembler\n",
      "ii  cuda-nvml-dev-12-0              12.0.140-1                        amd64        NVML native dev links, headers\n",
      "ii  cuda-nvprof-12-0                12.0.146-1                        amd64        CUDA Profiler tools\n",
      "ii  cuda-nvprune-12-0               12.0.140-1                        amd64        CUDA nvprune\n",
      "ii  cuda-nvrtc-12-0                 12.0.140-1                        amd64        NVRTC native runtime libraries\n",
      "ii  cuda-nvrtc-dev-12-0             12.0.140-1                        amd64        NVRTC native dev links, headers\n",
      "ii  cuda-nvtx-12-0                  12.0.140-1                        amd64        NVIDIA Tools Extension\n",
      "ii  cuda-opencl-12-0                12.0.140-1                        amd64        CUDA OpenCL native Libraries\n",
      "ii  cuda-opencl-dev-12-0            12.0.140-1                        amd64        CUDA OpenCL native dev links, headers\n",
      "ii  cuda-profiler-api-12-0          12.0.140-1                        amd64        CUDA Profiler API\n",
      "ii  cuda-sanitizer-12-0             12.0.140-1                        amd64        CUDA Sanitizer\n",
      "ii  cuda-toolkit-12-0-config-common 12.0.146-1                        all          Common config package for CUDA Toolkit 12.0.\n",
      "ii  cuda-toolkit-12-config-common   12.3.52-1                         all          Common config package for CUDA Toolkit 12.\n",
      "ii  cuda-toolkit-config-common      12.3.52-1                         all          Common config package for CUDA Toolkit.\n",
      "hi  libnccl-dev                     2.19.3-1+cuda12.0                 amd64        NVIDIA Collective Communication Library (NCCL) Development Files\n",
      "hi  libnccl2                        2.19.3-1+cuda12.0                 amd64        NVIDIA Collective Communication Library (NCCL) Runtime\n"
     ]
    }
   ],
   "source": [
    "! dpkg -l | grep cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# Do this one-time if you want CUDA, then restart/rerun notebook\n",
    "INSTALL_JAX_WITH_CUDA = False\n",
    "if INSTALL_JAX_WITH_CUDA:\n",
    "    # instruction from https://github.com/google/jax?tab=readme-ov-file#installation:\n",
    "    ! pip install -U \"jax[cuda12_pip]\" -f  \\\n",
    "        https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[cuda(id=0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Device: gpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"The Device: {jax.lib.xla_bridge.get_backend().platform}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"MPS available: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_printoptions(linewidth=150)\n",
    "np.set_printoptions(linewidth=150)\n",
    "jnp.set_printoptions(linewidth=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1701\n",
    "key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_copies = 20\n",
    "subkeys = jax.random.split(key, num=num_copies)\n",
    "key = subkeys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hippo_live import HiPPOCell, HiPPOLTI\n",
    "\n",
    "from cells_live import LSTMCell, BatchedGatedHiPPOCell, CharRNN\n",
    "\n",
    "from trans import initializer, legt, legs, lmu, lagt, fru, fout, foud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters For Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1\n",
    "freq = 10\n",
    "step = 1 / (28 * 28)  # 1e-3\n",
    "L = int(T / step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "data_size = L\n",
    "input_size = 1\n",
    "_block_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences = 100\n",
    "epochs = 10\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters For HiPPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset (TinyShakespeare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../datasets/shakespeare.txt\", \"r\", encoding=\"latin-1\") as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get all the unique characters that occur in this text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the unique characters: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "vocab size: 65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"all the unique characters:\", \"\".join(chars))\n",
    "print(f\"vocab size: {vocab_size:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a mapping from characters to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(s):\n",
    "    int_list = []\n",
    "    for c in s:\n",
    "        if c not in stoi:\n",
    "            raise ValueError(f\"character {c} not in vocabulary\")\n",
    "        else:\n",
    "            int_list.append(\n",
    "                stoi[c]\n",
    "            )  # encoder: take a string, output a list of integers\n",
    "    return int_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(l):\n",
    "    str_list = []\n",
    "    for i in l:\n",
    "        if i not in itos:\n",
    "            raise ValueError(f\"integer {i} not in the vocabulary\")\n",
    "        else:\n",
    "            str_list.append(\n",
    "                itos[i]\n",
    "            )  # decoder: take a list of integers, output a list of characters\n",
    "    return \"\".join(str_list)  # take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 46, 43, 1, 44, 53, 62, 1, 48, 59, 51, 54, 57, 1, 53, 60, 43, 56, 1, 58, 46, 43, 1, 50, 39, 64, 63, 1, 42, 53, 45, 8]\n",
      "The fox jumps over the lazy dog.\n"
     ]
    }
   ],
   "source": [
    "txt = \"The fox jumps over the lazy dog.\"\n",
    "print(encode(txt))\n",
    "print(decode(encode(txt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115394,)\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43 39\n",
      " 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 37\n",
      " 53 59]\n"
     ]
    }
   ],
   "source": [
    "data = jnp.array(encode(text))\n",
    "print(data.shape)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now split up the data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train has 1,003,854 tokens\n",
      "train has shape (1003854,)\n",
      "\n",
      "val has 111,540 tokens\n",
      "val has shape (111540,)\n"
     ]
    }
   ],
   "source": [
    "n = int(0.9 * len(data))  # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "print(f\"train has {len(train_data):,} tokens\")\n",
    "print(f\"train has shape {train_data.shape}\\n\")\n",
    "print(f\"val has {len(val_data):,} tokens\")\n",
    "print(f\"val has shape {val_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([18, 47, 56, 57, 58,  1, 15, 47, 58], dtype=int32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[: block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is [18] the target: 47\n",
      "when input is [18 47] the target: 56\n",
      "when input is [18 47 56] the target: 57\n",
      "when input is [18 47 56 57] the target: 58\n",
      "when input is [18 47 56 57 58] the target: 1\n",
      "when input is [18 47 56 57 58  1] the target: 15\n",
      "when input is [18 47 56 57 58  1 15] the target: 47\n",
      "when input is [18 47 56 57 58  1 15 47] the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1 : block_size + 1]\n",
    "for t in range(block_size):\n",
    "    context = x[: t + 1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(data, block_size=8):\n",
    "    # Trim the data to ensure that it is divisible by block_size for proper reshaping\n",
    "    num_complete_blocks = (data.size - 1) // block_size\n",
    "    trimmed_data_size = num_complete_blocks * block_size + 1\n",
    "    data = data[:trimmed_data_size]\n",
    "\n",
    "    # Prepare the input data 'x'\n",
    "    x = data[:-1].reshape(num_complete_blocks, block_size)\n",
    "\n",
    "    # Prepare the target data 'y'\n",
    "    # The target for each sequence in 'x' is the sequence shifted by one token\n",
    "    y = data[1:].reshape(num_complete_blocks, block_size)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1960"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq=batch_data(train_data, block_size=512)\n",
    "len(qq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\nSecond Citizen:\\nWould yo'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(qq[0][1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_target_relation(x_ds, y_ds, bs, block_size):\n",
    "    data_size = len(x_ds)\n",
    "    target_size = len(y_ds)\n",
    "    steps_per_epoch = data_size // bs\n",
    "\n",
    "    perms = jax.random.permutation(subkeys[0], data_size)\n",
    "    perms = perms[: steps_per_epoch * bs]  # skip incomplete batch\n",
    "    perms = perms.reshape((steps_per_epoch, bs))\n",
    "\n",
    "    for i, perm in enumerate(perms):\n",
    "        print(f\"inputs: {i}\")\n",
    "        print(x_ds[perm, ...].shape)\n",
    "        print(f\"{x_ds[perm, ...]}\\n\")\n",
    "        print(f\"targets: {i}\")\n",
    "        print(y_ds[perm, ...].shape)\n",
    "        print(y_ds[perm, ...])\n",
    "        print(\"----\")\n",
    "        for b in range(bs):  # batch dimension\n",
    "            for t in range(block_size):  # time dimension\n",
    "                context = x_ds[perm, ...][b, : t + 1]\n",
    "                target = y_ds[perm, ...][b, t]\n",
    "                print(f\"when input is {context.tolist()} the target: {target}\")\n",
    "        print(\"--------\")\n",
    "        if i == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_ds shape: (125481, 8)\n",
      "y_ds shape: (125481, 8)\n"
     ]
    }
   ],
   "source": [
    "x_ds, y_ds = batch_data(data=train_data, block_size=block_size)\n",
    "print(f\"x_ds shape: {x_ds.shape}\")\n",
    "print(f\"y_ds shape: {y_ds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e people'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(x_ds[30,:].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_target_relation(x_ds, y_ds, bs=4, block_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_rnn(cell_list, method: str, alpha: float = 2.0):\n",
    "    assert method in [\"legs\", \"legt\", \"lmu\", \"lagt\", \"fru\", \"fout\", \"foud\"]\n",
    "    init_fn = {\n",
    "        \"legs\": legs,\n",
    "        \"legt\": legt,\n",
    "        \"lmu\": lmu,\n",
    "        \"lagt\": lagt,\n",
    "        \"fru\": fru,\n",
    "        \"fout\": fout,\n",
    "        \"foud\": foud,\n",
    "        # \"chebt\": chebt,\n",
    "    }[method]\n",
    "\n",
    "    cell_args = [\n",
    "        {\n",
    "            \"hippo_cell\": HiPPOLTI,  # HiPPOLTICell,\n",
    "            \"hippo_args\": {\n",
    "                \"step_size\": step,\n",
    "                \"basis_size\": T,\n",
    "                \"alpha\": alpha,\n",
    "                # \"recon\": False,\n",
    "                \"A_init\": init_fn,\n",
    "                \"B_init\": init_fn,\n",
    "            },\n",
    "            \"tau_args\": {\n",
    "                \"features\": N,\n",
    "                \"bias\": True,\n",
    "                \"gate_fn\": sigmoid,\n",
    "                \"activation_fn\": tanh,\n",
    "                \"dtype\": jnp.float32,\n",
    "            },\n",
    "            # \"mlp_args\": {\n",
    "            #     \"features\": [1],\n",
    "            #     \"activation_fn\": relu,\n",
    "            #     \"bias\": False,\n",
    "            #     \"dtype\": jnp.float32,\n",
    "            # },\n",
    "            \"_tau\": LSTMCell,\n",
    "            \"bias\": True,\n",
    "            \"dtype\": jnp.float32,\n",
    "        }\n",
    "        for i in range(len(cell_list))\n",
    "    ]\n",
    "\n",
    "    rnn = CharRNN(\n",
    "        vocab_size=vocab_size,\n",
    "        hidden_size=N,\n",
    "        rnn_cells=cell_list,\n",
    "        cell_args=cell_args,\n",
    "    )\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_shaping():\n",
    "    # Define the model\n",
    "    model = initialize_rnn(\n",
    "        cell_list=[BatchedGatedHiPPOCell, BatchedGatedHiPPOCell],\n",
    "        method=\"legs\",\n",
    "        alpha=2.0,\n",
    "    )\n",
    "\n",
    "    # Define the input\n",
    "    input_data = jnp.ones((batch_size, block_size), dtype=jnp.int32)\n",
    "    print(f\"input data shape: {input_data.shape}\")\n",
    "\n",
    "    # Initialize the model carries\n",
    "    carries = model.initialize_carries(\n",
    "        rng=subkeys[7], batch_size=batch_size, hidden_sizes=[N, N]\n",
    "    )\n",
    "    print(f\"hidden shape: {carries}\")\n",
    "    print(f\"hidden shape: {carries[-1][0].shape}\")\n",
    "\n",
    "    # Initialize the model parameters\n",
    "    params = model.init(\n",
    "        subkeys[1],\n",
    "        x=input_data,\n",
    "        carry=carries,\n",
    "        targets=None,\n",
    "    )\n",
    "\n",
    "    # Initialize the model carries\n",
    "    carries = model.initialize_carries(\n",
    "        rng=subkeys[8], batch_size=batch_size, hidden_sizes=[N, N]\n",
    "    )\n",
    "    print(f\"hidden shape: {carries[-1][0].shape}\")\n",
    "\n",
    "    # Apply the model to the input\n",
    "    output, new_carries = model.apply(\n",
    "        params, x=input_data, carry=carries, targets=None\n",
    "    )\n",
    "\n",
    "    # Check the output shape\n",
    "    print(f\"output shape: {output.shape}\")\n",
    "    assert output.shape == (batch_size, block_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data shape: (64, 8)\n",
      "hidden shape: [(Array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), Array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)), (Array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), Array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))]\n",
      "hidden shape: (64, 128)\n",
      "hidden shape: (64, 128)\n",
      "output shape: (64, 8, 65)\n"
     ]
    }
   ],
   "source": [
    "test_shaping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "The cells below will be dedicated towards training a character-level RNN on a given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(state, carries, input, target, vocab_size, train=True):\n",
    "    def loss_fn(params):\n",
    "        # Use targets for teacher forcing if training\n",
    "        targets = target if train else None\n",
    "        logits, new_carries = state.apply_fn(\n",
    "            params, x=input, carry=carries, targets=targets\n",
    "        )\n",
    "\n",
    "        # One-hot encode the target with the correct vocabulary size\n",
    "        one_hot = jax.nn.one_hot(target, vocab_size)\n",
    "        loss = jnp.mean(optax.softmax_cross_entropy(logits=logits, labels=one_hot))\n",
    "        return loss, (logits, new_carries)\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, (logits, new_carries)), grads = grad_fn(state.params)\n",
    "\n",
    "    # Ensure accuracy calculation matches the target structure\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == target)\n",
    "    return grads, loss, accuracy, jnp.argmax(logits, axis=-1)\n",
    "\n",
    "if JIT:\n",
    "    apply_model = partial(jax.jit, static_argnames=[\"vocab_size\"])(apply_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model(state, grad):\n",
    "    return state.apply_gradients(grads=grad)\n",
    "\n",
    "if JIT:\n",
    "    update_model = jax.jit(update_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(rng, model, train_ds, state, vocab_size, batch_size=64):\n",
    "    \"\"\"Train for a single epoch.\"\"\"\n",
    "    train_x, train_y = train_ds\n",
    "    rng, permute_rng = jax.random.split(rng, 2)\n",
    "    data_size = len(train_x)\n",
    "    steps_per_epoch = data_size // batch_size\n",
    "    perms = jax.random.permutation(subkeys[0], data_size)\n",
    "    perms = perms[: steps_per_epoch * batch_size]  # skip incomplete batch\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "    epoch_loss = []\n",
    "    epoch_accuracy = []\n",
    "    for perm in tqdm(perms):\n",
    "        input = train_x[perm, ...]\n",
    "        target = train_y[perm, ...]\n",
    "        rng, carry_rng = jax.random.split(rng, 2)\n",
    "        carries = model.initialize_carries(\n",
    "            rng=carry_rng, batch_size=batch_size, hidden_sizes=[N, N]\n",
    "        )\n",
    "        # print('Apply model')\n",
    "        grads, loss, accuracy, _ = apply_model(\n",
    "            state=state,\n",
    "            carries=carries,\n",
    "            input=input,\n",
    "            target=target,\n",
    "            vocab_size=vocab_size,\n",
    "        )\n",
    "        # print('Update model')\n",
    "        state = update_model(state, grads)\n",
    "        epoch_loss.append(loss)\n",
    "        epoch_accuracy.append(accuracy)\n",
    "    train_loss = jnp.mean(jnp.array(epoch_loss))\n",
    "    train_accuracy = jnp.mean(jnp.array(epoch_accuracy))\n",
    "    return state, train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    epochs,\n",
    "    train_data,\n",
    "    test_data,\n",
    "    block_size,\n",
    "    vocab_size,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=64,\n",
    "):\n",
    "    # print('Checkpoints')\n",
    "    # # Define the directory where checkpoints will be stored\n",
    "    # checkpoint_dir = Path(\"/tmp/my_checkpoints\")\n",
    "    # options = ocp.CheckpointManagerOptions(max_to_keep=3, save_interval_steps=2)\n",
    "    # checkpoint_manager = ocp.CheckpointManager(\n",
    "    #     checkpoint_dir, {\"model_state\": ocp.PyTreeCheckpointer()}, options=options\n",
    "    # )\n",
    "\n",
    "    # Create the dataset\n",
    "    print('Creating dataset')\n",
    "    train_x, train_y = batch_data(data=train_data, block_size=block_size)\n",
    "    test_x, test_y = batch_data(data=test_data, block_size=block_size)\n",
    "    train_x_size = len(train_x)\n",
    "    steps_per_epoch = train_x_size // batch_size\n",
    "    decay_steps = steps_per_epoch * epochs\n",
    "\n",
    "    # Intialize the scheduler\n",
    "    print('Initializing scheduler, optimizer, model state')\n",
    "    schedule = optax.warmup_cosine_decay_schedule(\n",
    "        init_value=2e-3,\n",
    "        peak_value=2e-5,\n",
    "        warmup_steps=10,\n",
    "        decay_steps=decay_steps,\n",
    "        end_value=0.0,\n",
    "    )\n",
    "\n",
    "    # Initialization of the optimizer\n",
    "    optimizer = optax.adam(learning_rate)\n",
    "\n",
    "    # Initialize the model state\n",
    "    carries = model.initialize_carries(\n",
    "        rng=subkeys[7], batch_size=batch_size, hidden_sizes=[N, N]\n",
    "    )\n",
    "\n",
    "    print('Checkpoints')\n",
    "    state = None\n",
    "    starting_epoch = 0\n",
    "    if False:  # checkpoint_dir.exists():\n",
    "        lastest_step = checkpoint_manager.latest_step()\n",
    "        if lastest_step is not None:\n",
    "            # Restore the latest checkpoint\n",
    "            restored = checkpoint_manager.restore(lastest_step)\n",
    "            if restored is not None:\n",
    "                # Unpack the checkpointed state and set the starting epoch\n",
    "                state, starting_epoch = restored[\"model_state\"], restored[\"epoch\"]\n",
    "                print(f\"Resuming training from epoch {starting_epoch}\")\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"restored is None valued despite the checkpoint directory existing\"\n",
    "                )\n",
    "\n",
    "    else:\n",
    "        # checkpoint_dir.mkdir(\n",
    "        #     parents=True, exist_ok=True\n",
    "        # )  # Ensure the checkpoint directory is created\n",
    "\n",
    "        # Initialize the model parameters\n",
    "        params = model.init(\n",
    "            subkeys[1],\n",
    "            x=jnp.ones((batch_size, block_size), dtype=jnp.int32),\n",
    "            carry=carries,\n",
    "            targets=None,\n",
    "        )\n",
    "\n",
    "        state = train_state.TrainState.create(\n",
    "            apply_fn=model.apply, params=params, tx=optimizer\n",
    "        )\n",
    "        starting_epoch = 0\n",
    "        print(\"Starting training from scratch\")\n",
    "\n",
    "    # state = None\n",
    "    # starting_epoch = 0\n",
    "\n",
    "    print('Epochs')\n",
    "    rng = subkeys[7]\n",
    "    for epoch in range(starting_epoch, epochs):\n",
    "        print(f'Training epoch {epoch} / {epochs}')\n",
    "\n",
    "        rng, input_rng, carry_rng, test_rng = jax.random.split(rng, 4)\n",
    "        state, loss, accuracy = train_epoch(\n",
    "            rng=input_rng,\n",
    "            model=model,\n",
    "            train_ds=(train_x, train_y),\n",
    "            state=state,\n",
    "            vocab_size=vocab_size,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "        print('Testing epoch {epoch} / {epochs}')\n",
    "\n",
    "        indices = jax.random.randint(\n",
    "            test_rng,\n",
    "            shape=(batch_size,),\n",
    "            minval=0,\n",
    "            maxval=(test_x.shape[0] - 1),\n",
    "        )\n",
    "        test_input = test_x[indices, ...]\n",
    "        test_target = test_y[indices, ...]\n",
    "        carries = model.initialize_carries(\n",
    "            rng=carry_rng, batch_size=batch_size, hidden_sizes=[N, N]\n",
    "        )\n",
    "        _, test_loss, test_accuracy, test_logits = apply_model(\n",
    "            state=state,\n",
    "            carries=carries,\n",
    "            input=test_input,\n",
    "            target=test_target,\n",
    "            vocab_size=vocab_size,\n",
    "        )\n",
    "        print(\n",
    "            f\"Epoch: {epoch}\\n\\tTrain Loss: {loss}\\n\\tTrain Accuracy: {accuracy}\\n\\tTest Loss: {test_loss}\\n\\tTest Accuracy: {test_accuracy}\\n\\n\"\n",
    "        )\n",
    "        print(f\"Sample Model Text Output:\")\n",
    "        print(f\"------------------------------------------------------------\")\n",
    "        print(f\"{decode(test_logits[0].tolist())}\")\n",
    "        print(f\"------------------------------------------------------------\")\n",
    "        # checkpoint_manager.save(epoch, {\"model_state\": state})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hippo_list = [\n",
    "#     {\n",
    "#         \"name\": \"LegS-LSI\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"legs\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"LegS-LTI\",\n",
    "#         \"use\": True,\n",
    "#         \"val\": \"legs\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"LegT\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"legt\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"LMU\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"lmu\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"LagT\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"lagt\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"FRU\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"fru\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"FouT\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"fout\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"FouD\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"foud\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"ChebT\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"chebt\",\n",
    "#     },\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretization = [\n",
    "#     {\n",
    "#         \"name\": \"Forward-Euler\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": 0.0,\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"Backward-Euler\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": 1.0,\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"Bilinear\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": 0.5,\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"Zero-Order Hold\",\n",
    "#         \"use\": True,\n",
    "#         \"val\": 2.0,\n",
    "#     },\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_list = [BatchedGatedHiPPOCell, BatchedGatedHiPPOCell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing HiPPO-RNN with: LegS-LTI and ZOH...\n",
      "... Done!\n"
     ]
    }
   ],
   "source": [
    "class Discretizations:\n",
    "    FORWARD_EULER, BACKWARD_EULER, BILINEAR, ZOH = 0.0, 1.0, 0.5, 2.0\n",
    "\n",
    "print('Initializing HiPPO-RNN with: LegS-LTI and ZOH...')\n",
    "model = initialize_rnn(cell_list=cell_list, method='legs', alpha=Discretizations.ZOH)\n",
    "print('... Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset\n",
      "Initializing scheduler, optimizer, model state\n",
      "Checkpoints\n",
      "Starting training from scratch\n",
      "Epochs\n",
      "Training epoch 0 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                               | 0/30 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    epochs=epochs,\n",
    "    train_data=train_data,\n",
    "    test_data=val_data,\n",
    "    block_size=_block_size,\n",
    "    vocab_size=vocab_size,\n",
    "    learning_rate=lr,\n",
    "    batch_size=batch_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for hippo in hippo_list:\n",
    "#     if hippo[\"use\"]:\n",
    "#         alpha = -1.0\n",
    "#         for a in discretization:\n",
    "#             if a[\"use\"]:\n",
    "#                 alpha = a[\"val\"]\n",
    "#         print(f\"Running HiPPO-RNN with {hippo['name']} and {alpha}\")\n",
    "#         model = initialize_rnn(cell_list=cell_list, method=hippo[\"val\"], alpha=alpha)\n",
    "#         train(\n",
    "#             model=model,\n",
    "#             epochs=epochs,\n",
    "#             train_data=train_data,\n",
    "#             test_data=val_data,\n",
    "#             block_size=_block_size,\n",
    "#             vocab_size=vocab_size,\n",
    "#             learning_rate=lr,\n",
    "#             batch_size=batch_size,\n",
    "#         )\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
